
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content=""/>
<meta name="author" content="daniel berenberg"/>

<title>Daniel Berenberg - Website</title>

<!-- Custom styles for this template -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.1.0/css/bootstrap.min.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.1.0/js/bootstrap.min.js"></script>
<link rel="stylesheet" type="text/css" href="style.css">
<link href="css/scrolling-nav.css" rel="stylesheet">
</head>
    
  <!-- ######################## NAVBAR ####################### -->
  <body id="page-top">
    <!-- ############ PROJECTS ####################### -->
    <section id="projects">
        <div class="container">
        <h2 style="text-align:left; border-top: 2px solid rgba(1,1,1,0.2);">Featured Projects</h2>
            <p class="lead">Research projects I have recently worked on. 
          <div class="row">
             <div class="col-md-8">
               <div class="container">
                   <li>
                       <h3>
                            <a href="https://arxiv.org/abs/1810.03163">
                                Network fusion and causal characterization </a>
                             (Fall 2018)
                       </h3>
                   <ul>
                       <li>NetFUSES, a novel algorithm for <b>graph fusion</b>, the notion of performing
                       an alignment across multiple networks when node identities are ambiguous.</li>
                       <li>Analyzed causal interactions derived from large knowledge corpora
                       including English Wikidata and ConceptNet.</li>
                   </ul>
                </li>
              </div>
             </div>
            <div class="col-md-4">
                <img src="assets/imgs/wk_est.png">
            </div>
         <div class="row">
               <div class="container-fluid">
                   <div class="collapse multi-collapse" id="collapseExample">
                     <div class="card card-body">
                        <p>
                        In this project, we study and attempt to join distinct datasets of causal relationships, each
                        derived from various sources including knowledge graphs and crowdsourcing experiments.
                        </p>
                        <p>
                        Causality is extremely difficult identify in raw text on the computer for a host of reasons,
                        particularly due to the fact that causal relationships in this context 
                        are not verifiably true, but instead causal attributions submitted and supported by real people. 
                        For this reason, causal attributional relationships can be considered "noisy", inexact, 
                        and perhaps even false. 
                        </p>
                        <p>
                        In addition to the natural language and human error noise in causal attribution, 
                        causal relationships can be expressed in semantically identical yet
                        lexically dissimilar ways. For example, we can express two approximately 
                        semantically equivalent causal statemenets:<br/>
                        <div align="center">
                            <q>Rain</q> <i>causes</i> <q>Wet</q>
                            <br/>and<br/>
                            <q>Torrential Downpour</q> <i>causes</i> <q>Completely Soaked</q>
                        </div><br/>
                        While these statements may literally carry different meanings, in terms of causal attribution
                        we consider these statements to be synonymous.
                        In our study, we find thate each dataset not only contains distinct causal interactions
                        centered around the same concept (shown right), but that each knowledge graph  
                        is rife with semantically identical, lexically distinct relationships.
                        </p>
                        <div align="center">
                            <div class="col-md-10">
                                <figure class="collapse multi-collapse">
                                <img src="assets/imgs/Xcausal-cartoon.png">
                                <figcaption style="font-size:10pt;">
                                <i>Anecdotal example of dataset differences.</i><br/>
                                Here we see that the center node <q><b>anxiety</b></q> exhibits unique
                                structural characteristics and semantic relationships across each dataset.
                                </figcaption>
                                </figure>
                            </div>
                        </div>
                   </div>
                   <br/>
                   <p>
                    Much of the project is an attempt to fuse Wikidata and ConceptNet together in order to 
                    create a larget causal attribution knowledge base. 
                    This is acheived by using NetFUSES an algorithm for determining semantically 
                    equivalent nodes both across the two networks and internally. NetFUSES
                    utilizes a natural language processing tool called 
                    <a href="https://en.wikipedia.org/wiki/Sentence_embedding">Sentence embeddings</a>,
                    a method for mapping raw text into a high dimensional vector space where mathematical operations
                    on text become meaningful. In particular, we can measure the <b>similarity</b> between
                    two multiword expressions (such as <b>torrential downpour</b> and <b>rain</b>)
                    in order to fuse two semantically equivalent nodes.
                   </p>
                   <p>
                    After fusing the networks together, we perform a capture-recpature estimate to
                    infer the size of the <i>latent causal attribution network</i>. 
                    The latent causal attribution network is defined as the total causal attribution knowledge
                    base for the human population. 
                    Capture-recapture estimators are statistical techniques to infert the size of a population
                    given several samples of that population. 
                    In this case, our target population is the node set of the latent causal network
                    and the samples are Wikidata and Conceptnet. 
                    The fused graph I described earlier is
                    used to estimate the total overlap across the networks, a necessary metric for
                    the statistical estimators. 
                   </p>
                   <p>
                   Using these estimators, we were able to arrive at a numerical result and estimate for the number
                   of nodes and number of edges in the latent causal attribution graph as shown in the top image.
                   </p>
               </div>
               <button class="btn btn-warning" type="button" id="mybtn2"
                   data-toggle="collapse" data-target=".multi-collapse" 
                   aria-expanded="false" aria-controls="collapseExample">more info</button>
          <div class="row">
             <div class="col-md-8">
               <div class="container">
                   <li>
                       <h3>
                           <a href="https://github.com/abarson/WePanic-DL">WePanic</a> (Summer 2018)
                       </h3>
                       <ul>
                       <li style="text-align:left;">Successfully constructed a deep learning system capable of 
                           predicting human heart rate and respiratory rate from a smart phone video.</li>
                       <li>Implemented advanced video manipulation software using Python libraries such as OpenCV, PIL, NumPy, and SciPy.</li>
                       <li>Developed and tested neural networks using Keras and TensorFlow.</li>
                       <li>Publication in progress and TBA. </li>
                       </ul>
                   </li>
               </div>
               <div class="container-fluid">
                   <div class="collapse multi-collapse" id="collapseExample">
                     <div class="card card-body">
                       <p>The task alone deviates from the similar and widely researched 
                       <a href="https://en.wikipedia.org/wiki/Activity_recognition">action recognition</a> problem, 
                       not only because we must predict values from a continuous domain, but due to the shifted focus 
                       in spatiotemporal feature learning. <br/><br/> 
                       Traditionally, action recognition tends to lean on the spatial side, processing small chunks of a frame 
                       sequence at a time in order to build a general understanding. Here, succesful completion of the task requires 
                       the network to learn to recognize sequence data as a frequency, meaning larger frame sequences should be fed in, 
                       however the spatial information within a single frame of the sequence is relatively unimportant and can be downsampled.
                       <br/><br/>
                       Another interesting element of the project is the data itself. 
                       Though various standardization steps were taken, this data could be accurately classified as "extremely noisy". 
                       Not only were videos ranging in film quality, but label submissions (HR and RR) were problematic. 
                       Each subject was tasked with recording their own 30 second video and counting their heart rate and respiratory rate 
                       with the aid of a partner. 
                       This process understandably may introduce errors such as human counting inaccuracies, poor filming conditions, 
                       and timing errors. A timing error comes from the subject recording a video for longer or shorter than 30 seconds, 
                       but computing their breaths/beats on a minute basis. 
                       <br/><br/>
                       Finally, each subtask is uniquely understood by the neural network. In heart rate prediction, 
                       the network must learn to count beat frequencies across a specified time domain (in this case 6 seconds) 
                       and apply a simple transformation to its count (multiplication by 10, maybe) to reach a prediction.
                       Respiratory rates are a bit more complicated. Not only must the network learn to count beat frequency,
                       but it must also learn the complex, weakly linear relationship between the two labels. 
                       </p>
                     </div>
                   </div>
                   <br/>
                   <div id="left-btn">
                       <button class="btn btn-warning" type="button" id="mybtn"
                           data-toggle="collapse" data-target=".multi-collapse" 
                           aria-expanded="false" aria-controls="collapseExample">more info</button>
                   </div>
               </div>
             </div>

            <div class="col-md-4" style="border-top:none;">
                <img src="assets/wp_demo.gif">
                 <p style="font-size:10pt;" class="collapse multi-collapse">
                   <i style="font-size: 10.5pt">High performance neural network predictions across an entire video stream.</i>
                    <br/><i>Top Left</i>: Predictions and error rates. 
                    <br/><i>Bottom Right:</i> Processed input to the neural network. 
                    <br/><i>Background:</i> Originally recorded iPhone video.
                    <br/>
                    <br/>The actual value of subject's heart rate and respiratory rate are left static as they were directly submitted from the subject.
                </p>
               <figure class="collapse multi-collapse">
                 <img src="assets/imgs/dataset.jpg">
                 <figcaption style="font-size:10pt;">
                   <i style="font-size: 10.5pt">Label set distribution and structure.</i>
                    <br/><b>A</b> Dataset spread, each subject submits their heart rate and respiratory rate for their video submission. 
                    <br/><b>B</b> Violin plots showing the distribution of each label, noting the skew in respiratory rate specifically.
                 </figcaption>
               </figure>
             </div>
          </div>
          <div class="row">
             <div class="col-md-8">
               <div class="container">
                   <li>
                       <h3>
                            <a href="https://arxiv.org/abs/1805.06879">Correlation prediction</a> (Spring 2018)
                       </h3>
                   </li>
                   <!--
                   <ul>
                       <li>More info coming soon</li>
                   </ul>
                   -->
              </div>
          </div>
          </div>
          <div class="row">
             <div class="col-md-8">
               <div class="container">
                   <li>
                       <h3>
                            <a href="https://arxiv.org/abs/1810.03163">IPR Algorithm</a> (Spring 2018)
                       </h3>
                  </li>
                  <!--
                   <ul>
                       <li>More info coming soon</li>
                   </ul>
                  -->
              </div>
          </div>
    </section>
    <!-- ############ PROJECTS ####################### -->
    <!-- ############ BLOG ####################### -->
    <section id="blog">
        <div class="container">
        <h2 style="text-align:left; border-top: 2px solid rgba(1,1,1,0.2);">Blog</h2>
        <p class="lead">A space for describing smaller projects.</p>
        <a class="row" href="blog/map-filter-reduce.html" style="color:#000000; text-decoration:none;">
            <div class="col-md-4">
                <h4>Map, Filter, Reduce, and more</h4>
                <img src="assets/imgs/blog1_cover.png"> 
            </div>
            <div class="col-md-8">
                <br/>
                <p style="font-size: 18px;">
                Here I discuss functional approaches to computation in Python. i
                I show the power and usage of anonymous functions, describe use cases for 
                the map, filter, and reduce keywords and provide
                a host of other pieces of advice in regards to writing clear, concise, 
                and effective Python code. 
                <br/><br/>
                This blog assumes that the reader is a novice to intermediate Python programmer.
                </p>
            </div>
        </a>

        <a class="row" href="blog/trafslides.html" style="color:#000000; text-decoration:none;">
            <div class="col-md-4">
                <h4>Traffic Simulation</h4>
                <img src="assets/imgs/traf.png">
            </div>
            <div class="col-md-8">
                <br/>
                <p style="font-size: 18px;">
                These were some slides used to describe a model that investigates the
                interactions between fast and slow vehicles on a 2D-grid system. 
                This model is a cellular automata, a model characterized by locally 
                defined rules for entities to interact oftentimes on a lattice such as a 
                square grid. 
                Cellular Automata exhibit macro behavior and interesting patterns on a 
                global scale due to local interactions.</p>
            </div>
        </a>
    <br/>
        </div>
    </section>
    <!-- ############ BLOG ####################### -->
  </body>
</html>
